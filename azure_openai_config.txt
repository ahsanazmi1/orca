# Azure OpenAI Configuration for Orca Phase 3
# This file contains the Azure OpenAI configuration for LLM-powered explanations

# Azure OpenAI Endpoint
AZURE_OPENAI_ENDPOINT=https://orca-openai.openai.azure.com/

# Azure OpenAI API Key (replace with your actual key)
AZURE_OPENAI_API_KEY=your-api-key-here

# Azure OpenAI API Version
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Azure OpenAI Deployment Name (will need to be configured based on your deployment)
# IMPORTANT: Check your Azure OpenAI resource in the Azure portal to find the correct deployment name
# Common names: gpt-4, gpt-35-turbo, gpt-4o, gpt-4o-mini, text-davinci-003
# To find your deployment name:
# 1. Go to https://portal.azure.com
# 2. Navigate to your Azure OpenAI resource
# 3. Go to "Model deployments" section
# 4. Use the exact deployment name from the list
AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment-name-here

# Optional: Enable XGBoost model for production risk scoring
ORCA_USE_XGB=true

# Optional: Set deterministic seed for consistent results
ORCA_DETERMINISTIC_SEED=42

# To use this configuration:
# 1. Replace 'your-api-key-here' with the actual API key from Azure portal
# 2. Replace 'your-deployment-name-here' with the correct deployment name from Azure portal
# 3. Copy these environment variables to your shell or .env file
# 4. Or run: source azure_openai_config.txt
# 5. Test with: python -c "from src.orca_core.llm.explain import is_llm_configured; print('LLM configured:', is_llm_configured())"