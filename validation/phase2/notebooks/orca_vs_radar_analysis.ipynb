{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orca vs Radar Decision Engine Comparison\n",
    "\n",
    "This notebook provides a comprehensive analysis comparing the Orca Core decision engine with Radar's risk assessment system.\n",
    "\n",
    "## Analysis Overview\n",
    "- Decision accuracy comparison\n",
    "- Risk score correlation analysis\n",
    "- Performance metrics (ROC, PR curves)\n",
    "- Model calibration assessment\n",
    "- Processing time comparison\n",
    "- Feature importance analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set style\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ðŸ“Š Orca vs Radar Analysis Notebook\")\n",
    "print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load comparison data\n",
    "df = pd.read_csv(\"../data/radar_compare.csv\")\n",
    "\n",
    "print(\"ðŸ“ˆ Dataset Overview:\")\n",
    "print(f\"   Total transactions: {len(df)}\")\n",
    "print(f\"   Date range: {df['transaction_id'].min()} to {df['transaction_id'].max()}\")\n",
    "print(f\"   Amount range: ${df['amount'].min():.2f} - ${df['amount'].max():.2f}\")\n",
    "print(f\"   Currencies: {df['currency'].unique()}\")\n",
    "print(f\"   Rails: {df['rail'].unique()}\")\n",
    "print(f\"   Channels: {df['channel'].unique()}\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Accuracy Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision accuracy analysis\n",
    "decision_accuracy = df[\"decision_match\"].mean()\n",
    "print(f\"ðŸŽ¯ Overall Decision Accuracy: {decision_accuracy:.2%}\")\n",
    "\n",
    "# Decision distribution comparison\n",
    "orca_decisions = df[\"orca_decision\"].value_counts()\n",
    "radar_decisions = df[\"radar_decision\"].value_counts()\n",
    "\n",
    "print(\"\\nðŸ“Š Decision Distribution:\")\n",
    "print(\"Orca:\")\n",
    "for decision, count in orca_decisions.items():\n",
    "    print(f\"  {decision}: {count} ({count / len(df):.1%})\")\n",
    "\n",
    "print(\"\\nRadar:\")\n",
    "for decision, count in radar_decisions.items():\n",
    "    print(f\"  {decision}: {count} ({count / len(df):.1%})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
